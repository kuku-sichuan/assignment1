1. 在运用高效率编码或者计算时，一定要于有把握的结果比较，从而确定是否有错误。
2. 在全矩阵运算时，有2种实现方法！
3. SVM的dw向量矩阵实现中，这里的构造。
3. 在KNN中为什么一个循环的时间要比两个循环的时间要长？
4. 在超参数调整时，在log空间里的效果确实要好很多！
5. 这里有一个疑问，那就是在计算梯度的那里！在计算上的实现和推导出来的！
6. 对于RELU激活的神经元，我们必须要检查第一个隐藏层，有多少细胞死亡，不能死的
太多了。第一层是一旦死了，就永远完蛋了，至于其他隐藏层，存在疑问！
7. 为什么在SVM，softmax单独训练时中的训练中reg大的吓人？：我自己的理解
由于在单独SVM,softmax,模型复杂度比较低，{必须理解}十分重要！
8. 当学习率太小时，实际上reg对最后的结果改变不大！（lr*reg）这两者合适的组合
才是王道！
9. 在神经网络那里还需要优化！